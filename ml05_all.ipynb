{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "機械学習特論 第5回課題 k近傍法 SVM で アヤメのデータ、MNIST, Fashion-MNIST の分類を比較"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# google colab で実行する場合は、次の行の先頭の # を削除してこのブロックを実行する\n",
    "#!pip install japanize-matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn import metrics\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.datasets import fetch_openml\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn import svm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sklearnデータセットに収録されたiris(アヤメ)のデータセットをロードしてデータフレームを作成\n",
    "def load_iris_data():\n",
    "    data = load_iris()\n",
    "    x = pd.DataFrame(data[\"data\"],columns=data[\"feature_names\"])[50:150]\n",
    "    y = pd.DataFrame(data[\"target\"],columns=[\"target\"])[50:150] # species 1 2 を抽出\n",
    "    return x, y\n",
    "\n",
    "# 手書き文字のデータセットをダウンロードして、実験用データを準備 (70000枚のうち7000枚を利用)\n",
    "def load_mnist_data():\n",
    "    data = fetch_openml('mnist_784', version=1)\n",
    "    _x = np.array(data['data'].astype(np.float32))\n",
    "    _y = np.array(data['target'].astype(np.int32))\n",
    "    _, x, _, y = train_test_split(_x, _y, test_size=0.1, random_state=1, stratify=_y)\n",
    "    return x, y\n",
    "\n",
    "# Fashion-MNISTデータセットをダウンロードして、実験用データを準備 (70000枚のうち7000枚を利用)\n",
    "def load_fashion_mnist_data():\n",
    "    data = fetch_openml('Fashion-MNIST')\n",
    "    _x = np.array(data['data'].astype(np.float32))\n",
    "    _y = np.array(data['target'].astype(np.int32))\n",
    "    _, x, _, y = train_test_split(_x, _y, test_size=0.1, random_state=1, stratify=_y) \n",
    "    return x, y\n",
    "\n",
    "# 一括処理のためにデータセットの辞書を作成\n",
    "dataset = {'iris': load_iris_data(), 'mnist': load_mnist_data(), 'fashon-mnist': load_fashion_mnist_data()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 一括処理のためにモデルの辞書を作成\n",
    "model = {\n",
    "    # k近傍法のモデル\n",
    "    'kNN(k=3)':\n",
    "    KNeighborsClassifier(n_neighbors=3, # k を指定 (デフォルトは 5)\n",
    "                         weights='uniform',  # 距離を考慮しない(uniform:デフォルト)、する(distance)\n",
    "                         algorithm='auto', # 近傍点計算アルゴリズム (auto:デフォルト,ball_tree,kd_tree,brute)\n",
    "                         leaf_size=30,  # ball_tree,kd_tree指定時のリーフサイズの設定 (デフォルトは 30)\n",
    "                         p=2),  # 距離計算の次元 (2:デフォルト、1)\n",
    "    # svm (kernel=\"linear\", C=1.0) のモデル\n",
    "    'SVC(kernel=\"linear\", C=1)':\n",
    "    svm.SVC(kernel=\"linear\", C=1, max_iter=100000, verbose=True, random_state=1),\n",
    "    # svm (kernel=\"rbf\", C=1) のモデル\n",
    "    'SVC(kernel=\"rbf\", C=1)':\n",
    "    svm.SVC(kernel=\"rbf\", C=1, max_iter=100000, verbose=True, random_state=1),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "## dataset:iris  x_train:75 x_test:25 y_train:75 y_test:25\n",
      "dataset:iris model:kNN(k=3) accuracy_score: train_data: 0.92 test_data: 1.0\n",
      "[LibSVM]dataset:iris model:SVC(kernel=\"linear\", C=1) accuracy_score: train_data: 0.98667 test_data: 1.0\n",
      "[LibSVM]dataset:iris model:SVC(kernel=\"rbf\", C=1) accuracy_score: train_data: 0.93333 test_data: 0.96\n",
      "## dataset:mnist  x_train:5250 x_test:1750 y_train:5250 y_test:1750\n",
      "dataset:mnist model:kNN(k=3) accuracy_score: train_data: 0.96686 test_data: 0.93371\n",
      "[LibSVM]dataset:mnist model:SVC(kernel=\"linear\", C=1) accuracy_score: train_data: 1.0 test_data: 0.90971\n",
      "[LibSVM]dataset:mnist model:SVC(kernel=\"rbf\", C=1) accuracy_score: train_data: 0.9861 test_data: 0.94971\n",
      "## dataset:fashon-mnist  x_train:5250 x_test:1750 y_train:5250 y_test:1750\n",
      "dataset:fashon-mnist model:kNN(k=3) accuracy_score: train_data: 0.89295 test_data: 0.80286\n",
      "[LibSVM]dataset:fashon-mnist model:SVC(kernel=\"linear\", C=1) accuracy_score: train_data: 1.0 test_data: 0.79429\n",
      "[LibSVM]dataset:fashon-mnist model:SVC(kernel=\"rbf\", C=1) accuracy_score: train_data: 0.89638 test_data: 0.83429\n"
     ]
    }
   ],
   "source": [
    "# 辞書に格納したデータセットそれぞれについて性能を確認\n",
    "for dataset_key in dataset.keys():\n",
    "    # データを学習用と検証用に分割\n",
    "    x, y = dataset[dataset_key]\n",
    "    x_train, x_test, y_train, y_test = \\\n",
    "        train_test_split(x, y, test_size=0.25, random_state=1, stratify=y) # 検証用データに25%を割当て\n",
    "\n",
    "    print(f'## dataset:{dataset_key} ',\n",
    "          f'x_train:{len(x_train)} x_test:{len(x_test)} y_train:{len(y_train)} y_test:{len(y_test)}')\n",
    "\n",
    "    # 辞書に格納したモデルそれぞれについて性能を測定\n",
    "    for model_key in model.keys():\n",
    "        # 学習用データを利用してモデルを学習\n",
    "        clf = model[model_key]\n",
    "        clf = clf.fit(x_train, np.array(y_train).ravel()) \n",
    "\n",
    "        # 学習したモデルの性能(正答率)を学習用データと検証用データで評価\n",
    "        predict_train = clf.predict(x_train)\n",
    "        train_score = metrics.accuracy_score(y_train, predict_train)\n",
    "        predict_test = clf.predict(x_test)\n",
    "        test_score = metrics.accuracy_score(y_test, predict_test)\n",
    "        print(f'dataset:{dataset_key} model:{model_key}', \n",
    "            f'accuracy_score: train_data:{train_score: 0.5} test_data:{test_score: 0.5}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "## dataset:iris  x_train:75 x_test:25 y_train:75 y_test:25\n",
      "# no scaling\n",
      "dataset:iris model:kNN(k=3) accuracy_score: train_data: 0.92 test_data: 1.0\n",
      "[LibSVM]dataset:iris model:SVC(kernel=\"linear\", C=1) accuracy_score: train_data: 0.98667 test_data: 1.0\n",
      "[LibSVM]dataset:iris model:SVC(kernel=\"rbf\", C=1) accuracy_score: train_data: 0.93333 test_data: 0.96\n",
      "# with scaling\n",
      "dataset:iris model:kNN(k=3) accuracy_score: train_data: 0.93333 test_data: 0.96\n",
      "[LibSVM]dataset:iris model:SVC(kernel=\"linear\", C=1) accuracy_score: train_data: 0.96 test_data: 1.0\n",
      "[LibSVM]dataset:iris model:SVC(kernel=\"rbf\", C=1) accuracy_score: train_data: 0.94667 test_data: 1.0\n",
      "## dataset:mnist  x_train:5250 x_test:1750 y_train:5250 y_test:1750\n",
      "# no scaling\n",
      "dataset:mnist model:kNN(k=3) accuracy_score: train_data: 0.96686 test_data: 0.93371\n",
      "[LibSVM]dataset:mnist model:SVC(kernel=\"linear\", C=1) accuracy_score: train_data: 1.0 test_data: 0.90971\n",
      "[LibSVM]dataset:mnist model:SVC(kernel=\"rbf\", C=1) accuracy_score: train_data: 0.9861 test_data: 0.94971\n",
      "# with scaling\n",
      "dataset:mnist model:kNN(k=3) accuracy_score: train_data: 0.9459 test_data: 0.89771\n",
      "[LibSVM]dataset:mnist model:SVC(kernel=\"linear\", C=1) accuracy_score: train_data: 1.0 test_data: 0.91371\n",
      "[LibSVM]dataset:mnist model:SVC(kernel=\"rbf\", C=1) accuracy_score: train_data: 0.98552 test_data: 0.92743\n",
      "## dataset:fashon-mnist  x_train:5250 x_test:1750 y_train:5250 y_test:1750\n",
      "# no scaling\n",
      "dataset:fashon-mnist model:kNN(k=3) accuracy_score: train_data: 0.89295 test_data: 0.80286\n",
      "[LibSVM]dataset:fashon-mnist model:SVC(kernel=\"linear\", C=1) accuracy_score: train_data: 1.0 test_data: 0.79429\n",
      "[LibSVM]dataset:fashon-mnist model:SVC(kernel=\"rbf\", C=1) accuracy_score: train_data: 0.89638 test_data: 0.83429\n",
      "# with scaling\n",
      "dataset:fashon-mnist model:kNN(k=3) accuracy_score: train_data: 0.89352 test_data: 0.8\n",
      "[LibSVM]dataset:fashon-mnist model:SVC(kernel=\"linear\", C=1) accuracy_score: train_data: 1.0 test_data: 0.80057\n",
      "[LibSVM]dataset:fashon-mnist model:SVC(kernel=\"rbf\", C=1) accuracy_score: train_data: 0.91429 test_data: 0.82571\n"
     ]
    }
   ],
   "source": [
    "# 辞書に格納したデータセットそれぞれについて性能を確認\n",
    "for dataset_key in dataset.keys():\n",
    "    # データを学習用と検証用に分割\n",
    "    x, y = dataset[dataset_key]\n",
    "    x_train, x_test, y_train, y_test = \\\n",
    "        train_test_split(x, y, test_size=0.25, random_state=1, stratify=y) # 検証用データに25%を割当て\n",
    "    print(f'## dataset:{dataset_key} ',\n",
    "          f'x_train:{len(x_train)} x_test:{len(x_test)} y_train:{len(y_train)} y_test:{len(y_test)}')\n",
    "\n",
    "    # データ標準化なしで性能を測定\n",
    "    print('# no scaling')\n",
    "    # 辞書に格納したモデルそれぞれについて性能を測定\n",
    "    for model_key in model.keys():\n",
    "        # 学習用データを利用してモデルを学習\n",
    "        clf = model[model_key]\n",
    "        clf = clf.fit(x_train, np.array(y_train).ravel()) \n",
    "\n",
    "        # 学習したモデルの性能(正答率)を学習用データと検証用データで評価\n",
    "        predict_train = clf.predict(x_train)\n",
    "        train_score = metrics.accuracy_score(y_train, predict_train)\n",
    "        predict_test = clf.predict(x_test)\n",
    "        test_score = metrics.accuracy_score(y_test, predict_test)\n",
    "        print(f'dataset:{dataset_key} model:{model_key}', \n",
    "            f'accuracy_score: train_data:{train_score: 0.5} test_data:{test_score: 0.5}')\n",
    "\n",
    "    # データを標準化\n",
    "    print('# with scaling')\n",
    "    scaler = StandardScaler()\n",
    "    scaler.fit(x_train)\n",
    "    x_train = scaler.transform(x_train)\n",
    "    x_test = scaler.transform(x_test)\n",
    "\n",
    "    # 辞書に格納したモデルそれぞれについて性能を測定\n",
    "    for model_key in model.keys():\n",
    "        # 学習用データを利用してモデルを学習\n",
    "        clf = model[model_key]\n",
    "        clf = clf.fit(x_train, np.array(y_train).ravel()) \n",
    "\n",
    "        # 学習したモデルの性能(正答率)を学習用データと検証用データで評価\n",
    "        predict_train = clf.predict(x_train)\n",
    "        train_score = metrics.accuracy_score(y_train, predict_train)\n",
    "        predict_test = clf.predict(x_test)\n",
    "        test_score = metrics.accuracy_score(y_test, predict_test)\n",
    "        print(f'dataset:{dataset_key} model:{model_key}', \n",
    "            f'accuracy_score: train_data:{train_score: 0.5} test_data:{test_score: 0.5}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "18ef0afcf35f1452430268c7ef685ac367525865953635d3b087fb3264879c09"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
